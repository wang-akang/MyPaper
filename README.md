
###多标签图像分类：
1. [2023ICKV] **PatchCT：将补丁集和标签集与条件传输对齐
用于多标签图像分类**[[纸]](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf)
2. [2023ICKV] **CDUL：用于多标签图像分类的剪辑驱动无监督学习**[[纸]](https://arxiv.org/pdf/2307.16634)[[代码]](https://github.com/cs-mshah/CDUL)
3. [2024ICML] **语言驱动的跨模态分类器
零拍多标记图像识别**[[纸]](https://openreview.net/pdf?id=sHswzNWUW2)[[代码]](https://github.com/yic20/CoMC)
4. [2024AAAI] **TagCLIP：一个本地到全球的框架，在不训练的情况下增强CLIP的开放词汇多标签分类**[[纸]](https://arxiv.org/pdf/2312.12828)[[代码]](https://github.com/linyq2117/TagCLIP)
5. [2025CVPR] **SPARC：视觉语言模型中零击多标签识别的分数提示和自适应融合**[[纸]](https://arxiv.org/pdf/2502.16911?)[[代码]](https://github.com/kjmillerCURIS/SPARC)
6. [2025CVPR] **分类器引导的CLIP蒸馏在无监督多标记分类中的应用**[[纸]](https://arxiv.org/pdf/2503.16873)[[代码]](https://github.com/k0u-id/CCD)
7. [2025CVPR] **恢复和匹配：开放词汇多标签识别
知识约束最优运输**[[纸]](https://arxiv.org/pdf/2503.15337)[[代码]](https://github.com/EricTan7/RAM)
8. [2025CVPR] **多标签的相关和判别标签分组
视觉提示微调**[[纸]](https://arxiv.org/pdf/2504.09990)
9. [2025年ICML] **从局部细节到全局语境：基于注意选择的视觉语言模型**[[纸]](https://arxiv.org/pdf/2505.13233?)[[代码]](https://github.com/BIT-DA/ABS)
10. [2025WACV] **关注你的邻居：免训练的开放词汇语义分割**[[纸]](https://arxiv.org/pdf/2404.08181?)[[代码]](https://github.com/sinahmr/NACLIP)
11. [2025ICKV] **长尾多标签图像分类的分类选择特征增强**
12. [未知的] **用于免训练的开放词汇切分的自校准CLIP**[[纸]](https://arxiv.org/pdf/2411.15869)[[代码]](https://github.com/SuleBai/SC-CLIP)
13. [2024CVPR] **离线扩散增强原型生成的免训练开放词汇切分**[[纸]](https://arxiv.org/pdf/2404.06542)[[代码]](https://github.com/aimagelab/freeda/)
14. [未知的] **TextRegion：来自冻结图像-文本模型的文本对齐区域标记**[纸](https://arxiv.org/pdf/2505.23769)[代码](https://github.com/avaxiao/TextRegion)
---


### Training-Free：
目前的traning-free方法的核心其实就是算相似度矩阵
1. [2024 CVPR] **Clip-diy: Clip dense inference yields open-vocabulary semantic segmentation for-free** [[paper]](https://arxiv.org/pdf/2309.14289)
2. [2024 CVPR] **Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation** [[paper]]-(https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10655445&tag=1) [[code]](https://github.com/aimagelab/freeda) 
3. [2024 ECCV] **Proxyclip: Proxy attention improves clip for open-vocabulary segmentation** [[paper]](https://arxiv.org/pdf/2408.04883) [[code]](https://github.com/mc-lan/ProxyCLIP?tab=readme-ov-file)
4. [2024 ECCV] **ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference** [[paper]](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06346.pdf) [[code]](https://github.com/mc-lan/ClearCLIP)
5. [2024 ECCV] **Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2404.08181) [[code]](https://github.com/sinahmr/NACLIP)
6. [2024 ECCV] **SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference** [[paper]](https://arxiv.org/pdf/2312.01597) [[code]](https://github.com/wangf3014/SCLIP)
7. [2024 ECCV] **Explore the Potential of CLIP for Training-Free Open Vocabulary Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2407.08268) [[code]](https://github.com/leaves162/CLIPtrase)
8. [2025 arXiv] **Self-Calibrated CLIP for Training-Free Open-Vocabulary Segmentation** [[paper]](https://arxiv.org/pdf/2411.15869) [[code]](https://github.com/SuleBai/SC-CLIP?tab=readme-ov-file)
9. [2025 CVPR] **LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2503.19777) [[code]](https://github.com/vladan-stojnic/LPOSS)
10. [2025 CVPR] **ResCLIP: Residual Attention for Training-free Dense Vision-language Inference** [[paper]](https://arxiv.org/pdf/2411.15851) [[code]](https://github.com/yvhangyang/ResCLIP?tab=readme-ov-file)
11. [2025 CVPR] **Distilling Spectral Graph for Object-Context Aware Open-Vocabulary Semantic Segmentation** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Distilling_Spectral_Graph_for_Object-Context_Aware_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf) [[code]](https://github.com/MICV-yonsei/CASS)
12. [2025 CVPR] **Cheb-GR: Rethinking k-nearest neighbor search in Re-ranking for Person Re-identification** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Cheb-GR_Rethinking_K-nearest_Neighbor_Search_in_Re-ranking_for_Person_Re-identification_CVPR_2025_paper.pdf) [[code]](https://github.com/Jinxi-Yang-WHU/Fast-GCR.git) 
> 笔记：本文提到的很多re-ranking的技术就是对直接计算的相似度矩阵进行更新，前面公式搞了一大堆，最后就是一个特征传播。
14. [2025 CVPR] **Realistic Test-Time Adaptation of Vision-Language Models** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.pdf) [[code]](https://github.com/MaxZanella/StatA) [[original]](https://arxiv.org/pdf/2406.01837)
15. [2025 ICLR] **Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model** [[paper]](https://arxiv.org/pdf/2412.18303) [[code]](https://github.com/Yushu-Li/ECALP?tab=readme-ov-file)
16. [2025 arXiv] **Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2505.21844v1) [[code]](https://github.com/dosowiechi/MLMP?tab=readme-ov-file)

### 语义分割:
1. [2025CVPR] **Test-Time Adaptation of Vision-Language Models forOpen-Vocabulary Semantic Segmentation** [[paper]](https://arxiv.org/pdf/2505.21844v1)


### 老师提供暂存：
1. [2025 arXiv] **POT: Prototypical Optimal Transport for Weakly Supervised Semantic Segmentation** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_POT_Prototypical_Optimal_Transport_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf)
> 弱监督病理图像的语义分割
2. [2025CVPR] **Multi-Label Prototype Visual Spatial Search for Weakly Supervised Semantic Segmentation** [[paper]](https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Multi-Label_Prototype_Visual_Spatial_Search_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf)
> 弱监督病理图像的语义分割
3. [2024 arXiv]**Toward Modality Gap: Vision Prototype Learning for Weakly-supervised Semantic Segmentation with CLIP** [[paper]](https://arxiv.org/pdf/2412.19650)
4. [2025CVPR]**Prompt Categories Cluster for Weakly Supervised Semantic Segmentation** [[paper]](https://openaccess.thecvf.com/content/CVPR2025W/eLVM/papers/Wu_Prompt_Categories_Cluster_for_Weakly_Supervised_Semantic_Segmentation_CVPRW_2025_paper.pdf)
5. [2025 arXiv]  **2025-NIPS-Disentangling CLIP for Multi-Object Perception** [[paper]](https://arxiv.org/html/2502.02977v3)


### 3D点云处理和视觉-语言模型
1. [2025-ICCV] **Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation**
2. [2025-ICCV] **Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval**
3. [2025-ICCV] **Partially Matching Submap Helps: Uncertainty Modeling and Propagation for Text to Point Cloud Localization**
4. [2025-ICCV] **Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds**
5. [2025-CVPR] **Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model**
6. [2025-arXiv] **Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation**  [[paper]](https://arxiv.org/html/2506.22375v1)
7. [2025-ICLR] **MULTIMODALITY HELPS FEW-SHOT 3D POINT CLOUD SEMANTIC SEGMENTATION** [[paper]](https://arxiv.org/pdf/2410.11414)
8. [2025-ICML] **SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds**
9. [2025-CVPR] **Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis**
10. [2025-CVPR] **Purge-Gate: Efficient Backpropagation-Free Test-Time Adaptation for Point Clouds via Token Purging**
11. [2025-ICCV] **Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval**

